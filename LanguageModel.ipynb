{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LanguageModel.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwO1qkvTW7Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQPFqXtUW7Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import\n",
        "with open(\"littleprince.txt\", \"r\",encoding='utf-8') as file:\n",
        "    d = file.read()\n",
        "\n",
        "## Cleansing\n",
        "d = d.lower()\n",
        "d = re.sub(r'[^a-zA-Z.\\s]', ' ', d)\n",
        "d = d.replace('\\n','').replace('  ',' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48ivr10W7Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove punctuation\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "token = tokenizer.tokenize(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV1H_H2rW7Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove stop words\n",
        "\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "\n",
        "w_token = word_tokenize(d)\n",
        "\n",
        "w_token_filtered =[]\n",
        "for w in token:\n",
        "    if w not in stop_words:\n",
        "        w_token_filtered.append(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXYG39DeW7T1",
        "colab_type": "code",
        "colab": {},
        "outputId": "961e7bec-188c-4508-f902-0b97f93d5809"
      },
      "source": [
        "trigram = list(ngrams(w_token_filtered, 3))\n",
        "\n",
        "fdist = FreqDist(trigram)\n",
        "print(fdist)\n",
        "fdist.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<FreqDist with 6980 samples and 7306 outcomes>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('said', 'little', 'prince'), 47),\n",
              " (('asked', 'little', 'prince'), 11),\n",
              " (('good', 'morning', 'said'), 11),\n",
              " (('little', 'prince', 'said'), 9),\n",
              " (('little', 'prince', 'added'), 6),\n",
              " (('little', 'prince', 'went'), 6),\n",
              " (('concerned', 'matters', 'consequence'), 5),\n",
              " (('little', 'prince', 'asked'), 5),\n",
              " (('planet', 'little', 'prince'), 5),\n",
              " (('one', 'never', 'knows'), 5)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlq0j4kDW7T8",
        "colab_type": "code",
        "colab": {},
        "outputId": "3587d90c-4e5a-48e8-9a19-ee67cefcd6df"
      },
      "source": [
        "mle = nltk.probability.MLEProbDist(fdist)\n",
        "add1 = nltk.probability.LaplaceProbDist(fdist)\n",
        "kns = nltk.probability.KneserNeyProbDist(fdist)\n",
        "\n",
        "print('No Smoothing : ',fdist.freq(('said', 'little', 'prince')))\n",
        "    ## 47 / 7306\n",
        "print('No Smoothing unseen : ',fdist.freq(('king', 'queen', 'jack')))\n",
        "print('MLE : ',mle.prob(('said', 'little', 'prince')))\n",
        "    ##47 / 7306\n",
        "print('Add-1 Smoothing : ',add1.prob(('said', 'little', 'prince')))\n",
        "    ## 47 / (7306+6980)\n",
        "print('Add-1 Smoothing unseen : ',add1.prob(('king', 'queen', 'jack')))\n",
        "print('Kneser-Ney Smoothing : ',kns.prob(('said', 'little', 'prince')))\n",
        "print('Kneser-Ney Smoothing unseen : ',kns.prob(('king', 'queen', 'jack')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Smoothing :  0.006433068710648782\n",
            "No Smoothing unseen :  0.0\n",
            "MLE :  0.006433068710648782\n",
            "Add-1 Smoothing :  0.0033599328013439733\n",
            "Add-1 Smoothing unseen :  6.999860002799944e-05\n",
            "Kneser-Ney Smoothing :  0.9635416666666666\n",
            "Kneser-Ney Smoothing unseen :  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xFaSIp7W7T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}