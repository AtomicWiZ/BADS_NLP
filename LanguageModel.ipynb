{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LanguageModel.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOA6Pr2K5RtS",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AtomicWiZ/BADS_NLP/blob/master/LanguageModel.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwO1qkvTW7Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9_LX1furWOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download one-time\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQPFqXtUW7Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "git_url = \"https://raw.githubusercontent.com/AtomicWiZ/BADS_NLP/master/littleprince.txt\"\n",
        "\n",
        "## Import\n",
        "d = requests.get(git_url).content.decode('utf8')\n",
        "\n",
        "## Cleansing\n",
        "d = d.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48ivr10W7Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove punctuation\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "# tokenize by regular expression. split string into substring\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "# \\w = any one word/non-word character. including numerical character\n",
        "\n",
        "token = tokenizer.tokenize(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV1H_H2rW7Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove stop words\n",
        "\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "\n",
        "w_token_filtered =[]\n",
        "for w in token:\n",
        "    if w not in stop_words:\n",
        "        w_token_filtered.append(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXYG39DeW7T1",
        "colab_type": "code",
        "outputId": "faf6670d-d2b1-493e-864d-fddb4ed85a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trigram = list(ngrams(w_token_filtered, 3))\n",
        "\n",
        "fdist = FreqDist(trigram)\n",
        "print(fdist)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<FreqDist with 7011 samples and 7337 outcomes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlq0j4kDW7T8",
        "colab_type": "code",
        "outputId": "ed73cb20-acba-4fcf-f53f-8894bd77cb2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "mle = nltk.probability.MLEProbDist(fdist)\n",
        "add1 = nltk.probability.LaplaceProbDist(fdist)\n",
        "kns = nltk.probability.KneserNeyProbDist(fdist)\n",
        "\n",
        "query_text = ('said', 'little', 'prince')\n",
        "unseen_text = ('king', 'queen', 'jack')\n",
        "\n",
        "print(type(query_text))\n",
        "\n",
        "print('MLE : ',mle.prob(query_text))\n",
        "    ## 47 / 7337\n",
        "print('Add-1 Smoothing : ',add1.prob(query_text))\n",
        "    ## (47+1) / (7337+7011)\n",
        "print('Kneser-Ney Smoothing : ',kns.prob(query_text))\n",
        "    ## prob that 'said little' will follow by 'prince'\n",
        "    ## prob that 'wi-2 wi-1' will follow by wi\n",
        "\n",
        "print('MLE unseen : ',mle.prob(unseen_text))\n",
        "print('Add-1 Smoothing unseen : ',add1.prob(unseen_text))\n",
        "    ## 1 / (7337+7011)\n",
        "print('Kneser-Ney Smoothing unseen : ',kns.prob(unseen_text)) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "MLE :  0.006405887965108355\n",
            "Add-1 Smoothing :  0.003345413994981879\n",
            "Kneser-Ney Smoothing :  0.9635416666666666\n",
            "MLE unseen :  0.0\n",
            "Add-1 Smoothing unseen :  6.969612489545581e-05\n",
            "Kneser-Ney Smoothing unseen :  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxehDdt2t0Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7cea2d81-51cc-4aac-8a32-fc4f6062b409"
      },
      "source": [
        "prob_sum = 0\n",
        "# list all samples with non zero probabilities\n",
        "for i in kns.samples():\n",
        "    if i[0] == \"said\" and i[1] == \"little\":\n",
        "        # sum prob of trigram that begin with 'said little'\n",
        "        prob_sum += kns.prob(i)\n",
        "        print(\"{0}:{1}\".format(i, kns.prob(i)))\n",
        "print('Total prob : ',prob_sum)\n",
        "# save some probabilitity mass for the smoothing algorithm to distribute to the unseen  N-grams"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('said', 'little', 'prince'):0.9635416666666666\n",
            "('said', 'little', 'frightened'):0.005208333333333333\n",
            "Total prob :  0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}